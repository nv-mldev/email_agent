# ğŸ“§ Email Agent - Auto-Read, Summarizer & Attachment Extractor

> **A comprehensive email processing system that automatically reads emails, generates summaries, and extracts attachments for further processing.**

## âœ¨ Features

- ğŸ“¬ **Automated Email Reading** - Monitors and reads incoming emails
- ğŸ“ **AI-Powered Summarization** - Generates concise email summaries
- ğŸ“ **Attachment Extraction** - Securely extracts and processes email attachments
- ğŸ”„ **Real-time Processing** - Uses RabbitMQ for efficient message queuing
- ğŸŒ **Microsoft Graph Integration** - Seamless integration with Office 365

## ğŸ“ Project Structure

```
ğŸ“‚ email_agent/
â”œâ”€â”€ ğŸ”§ .env.example
â”œâ”€â”€ ğŸ“‹ requirements.txt
â”œâ”€â”€ ğŸ .venv/
â”œâ”€â”€ ğŸ“§ email_polling_service/
â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”œâ”€â”€ âš™ï¸ config.py
â”‚   â”œâ”€â”€ ğŸŒ graph_client.py
â”‚   â”œâ”€â”€ â–¶ï¸ main.py
â”‚   â”œâ”€â”€ ğŸ° rabbitmq_client.py
â”‚   â””â”€â”€ ğŸ”§ service.py
â”œâ”€â”€ ğŸ—‚ï¸ email_parser/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ parser.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ ğŸ“ summarizer/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ summarizer.py
â”œâ”€â”€ ğŸ“ attachment_handler/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ handler.py
â”œâ”€â”€ ğŸ·ï¸ document_identifier/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ identifier.py
â”œâ”€â”€ ğŸ”— extraction_apis/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ invoice_extractor.py
â”‚   â”œâ”€â”€ po_extractor.py
â”‚   â””â”€â”€ ewaybill_extractor.py
â”œâ”€â”€ ğŸ–¥ï¸ ui_dashboard/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ src/
â””â”€â”€ ğŸ—ƒï¸ database/
   â”œâ”€â”€ models.py
   â””â”€â”€ migrations/
```

## Flowchart

```mermaid
graph TD
    A[Cron Scheduler triggers script every X minutes] --> B{Run poll_emails.py};
    B --> C[Initialize Clients: MS Graph & RabbitMQ];
    C --> D[Fetch Unread Emails via Graph API];
    D --> E{For each Unread Email};
    E -- Yes --> F[Construct JSON Payload];
    F --> G[Publish Message to RabbitMQ];
    G --> H[Mark Email as Read via Graph API];
    H --> E;
    E -- No more emails --> I[Log Completion & Exit];
    B -- On Error --> J[Log Error & Exit];

    subgraph "Execution Script (poll_emails.py)"
        C
        D
        E
        F
        G
        H
        I
        J
    end
```

## ğŸ“‹ File Descriptions

| File | Description |
|------|-------------|
| ğŸ”§ **config.py** | Handles loading all configurations from environment variables |
| ğŸŒ **graph_client.py** | Contains refactored code to interact with MS Graph API |
| ğŸ° **rabbitmq_client.py** | Utility to manage RabbitMQ connection and message publishing |
| ğŸ”§ **service.py** | Core logic for the email polling service |
| â–¶ï¸ **main.py** | Entry point to start the service |

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Microsoft Azure account with Graph API access
- RabbitMQ server

### Installation

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd email_agent
   ```

2. **Create virtual environment**

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**

   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

5. **Run the service**

   ```bash
   python email_polling_service/main.py
   ```

## âš™ï¸ Configuration

Set up the following environment variables in your `.env` file:

```env
# Microsoft Graph API
AZURE_TENANT_ID=your_tenant_id
AZURE_CLIENT_ID=your_client_id
AZURE_CLIENT_SECRET=your_client_secret

# RabbitMQ
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USERNAME=guest
RABBITMQ_PASSWORD=guest

# Email Configuration
MAILBOX_ADDRESS=your_email@domain.com
```

## System Architecture and Design (Revised)

This document details the architecture for an AI agent that processes emails from a designated inbox, identifies document types, and then presents them to a user for confirmation before final data extraction.

### Component Breakdown (Revised)

This revised flow places the automated document identification before the user interaction step.

#### ğŸ“¨ Email Polling Service

- Continuously monitors the `hello@cargoa.io` inbox for new emails.
- Can use webhooks (real-time) or scheduled polling.

#### ğŸ—‚ï¸ Email Parser

- Extracts key information from new emails:
  - Sender
  - Subject
  - Body
  - Attachments

#### ğŸ“ Email Summarizer

- Passes the email body to a large language model (LLM).
- Generates a concise summary for user context on the UI dashboard.

#### ğŸ“ Attachment Handler

- Securely transfers attachments to cloud storage (e.g., AWS S3, Google Cloud Storage).
- Ensures original files are saved before processing.

#### ğŸ·ï¸ Document Identifier

- Analyzes stored attachments using a machine learning model.
- Automatically identifies document type (e.g., Invoice, Purchase Order, E-way Bill).

#### ğŸ–¥ï¸ UI Dashboard

- Main interface for human-in-the-loop.
- Displays:
  - Email summary
  - List of attachments
  - Predicted document type for each attachment

#### ğŸ‘¤ Human Confirmation

- User reviews dashboard information.
- Confirms or overrides predicted document type.
- Confirmation triggers the next processing stage.

#### ğŸ”— Extraction APIs

- Upon confirmation, dispatches documents to specific extraction APIs:
  - ğŸ§¾ Invoice Extraction API
  - ğŸ“„ Purchase Order Extraction API
  - ğŸšš E-way Bill Extraction API

#### ğŸ—ƒï¸ Processed Data

- Final structured data is stored in a database or sent to downstream systems.

## Development and Deployment Strategy

The technology stack and deployment strategy remain robust and suitable for this workflow.

### ğŸ› ï¸ Technology Stack

- **Backend:** Python (TensorFlow, PyTorch, Scikit-learn, Flask, Django)
- **Frontend:** React or Vue.js for the interactive UI dashboard
- **AI/ML Models:**
  - Email Summarization: Pre-trained LLMs (OpenAI GPT, Google Gemini, Hugging Face)
  - Document Identification: Custom models (TensorFlow, PyTorch) or cloud AI services (Google Cloud Vision AI, AWS Rekognition)
- **Storage:** Cloud object storage (AWS S3, Google Cloud Storage, Azure Blob Storage)

### âš™ï¸ Deployment

- **Containerization:** Docker for packaging microservices
- **Orchestration:** Kubernetes (Amazon EKS, Google GKE, Azure AKS)
- **CI/CD:** GitHub Actions, Jenkins, or GitLab CI
- **Monitoring:** Prometheus (metrics), Grafana (visualization), ELK Stack (logging)

## POSTGRESQL

### Creating Tables

```bash
sudo -u postgres psql 
CREATE ROLE cargoa_user WITH LOGIN PASSWORD 'mysecretpassword';
CREATE DATABASE email_agent WITH OWNER = cargoa_user;
```

### Deleting the Tables in Postgresql

```bash
sudo -u postgres psql -c "DROP DATABASE email_agent;"
```

or

```bash
sudo -u postgres psql
DROP DATABASE email_agent;
\q
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

> Made with â¤ï¸ for efficient email processing
